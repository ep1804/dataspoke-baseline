# DataSpoke Baseline

AI Data Catalog Starter: Productized Scaffold to Generate Custom Solutions

![DataSpoke Concept](../assets/dataspoke_concept.jpg)

---

## 1. 배경

### 맞춤형 솔루션의 필요성

데이터 카탈로그 솔루션(e.g. DataHub, Dataplex, OpenMetadata)은 방대한 기능을 제공하나, 실제 현장 활용도는 그 기능 수준에 비하면 낮은 경우가 많다. 이는 모두를 만족시키려다 누구에게도 최적화되지 못한 인터페이스가 되었기 때문이다.

- 데이터 사용자 그룹의 요구는 다양하다. 데이터 엔지니어는 파이프라인의 세부 기술 스펙과 비용을 보고 싶고, ML Engineer와 데이터 분석가는 text-to-SQL을 위해 충분한 도메인 정보가 담긴 메타데이터를 원한다. 데이터 스튜어드는 거버넌스를 위해 데이터 가용성 수치(다운타임 등)와 품질 검사 결과 이력을 모니터링하고 싶고, 보안팀은 PII(개인정보) 활용 현황을 한눈에 보고 싶다. 아무리 잘 설계된 UI라 해도 이렇게 다양한 목적을 소화하면서 쉽고 편리한 사용성을 유지하기는 어렵다.

- UI 차원을 넘어서 각 사용자는 도메인에 특화된 추가 기능을 원하는 경우도 많다. ML 기반의 데이터 품질 점검 모듈을 맞춤형으로 작성하여 데이터 카탈로그에서 구동하려 하거나, 기존 메타 수집(ingestion) 구조에 맞지 않는 특이한 데이터 소스를 등록해야 할 수도 있다.

### AI 시대 데이터 카탈로그의 새로운 요구 조건

LLM과 AI 에이전트가 실무에 도입됨에 따라, 데이터 카탈로그는 단순 메타데이터 저장소를 넘어 다음 두 가지 핵심 기능을 수행해야 한다.

- **Online Verifier (실시간 검증)**: AI 코딩 루프 내에서 파이프라인 개발 결과물을 실시간 검증하는 기능이다. RAG나 MCP(Model Context Protocol)를 통해 카탈로그를 코딩 루프에 연결함으로써, TDD(테스트 주도 개발) 방식처럼 데이터 검증 도구를 먼저 설정하고 파이프라인을 개발하는 워크플로우를 구현한다.

- **Self-Organization & Self-Purification (자기 조직화 및 자기 정화)**: AI를 활용해 데이터 택소노미(Taxonomy) 및 온톨로지(Ontology)를 설계하고, 정합성을 스스로 점검·교정하는 기능이다. 비즈니스 데이터가 복잡해짐에 따라 이를 전사 체계에 실시간 반영하고, 주변 환경 변화에 맞춰 테이블 및 컬럼 정의를 최신화해야 한다. 데이터 카탈로그는 이러한 정화 작업을 수행하기에 가장 적합한 컴포넌트다.

## 2. 프로젝트 정의

본 프로젝트는 코딩 에이전트를 활용하여 맞춤형 데이터 카탈로그를 빠르게 제작할 수 있는 틀을 제공함으로써, 위에서 제기한 맞춤형 카탈로그 문제를 해결하려 한다.

프로젝트명 **DataSpoke**는 기존 DataHub를 중심(Hub)으로 두고, 각 조직의 니즈에 맞춘 특화 확장판을 바퀴살(Spoke)로 정의하는 구조에서 비롯되었다.

이 저장소에 담기는 산출물은 다음 두 가지이다.

- **Baseline Product** — AI 시대의 카탈로그가 갖춰야 할 필수 기능을 사전 구현한 것이다. 데이터 엔지니어(DE), 데이터 분석가(DA), 데이터 거버넌스 담당자(DG)를 주요 타깃으로 한다.
- **AI Scaffold** — 일관된 컨벤션, 개발 스펙, 환경 설정, Claude Code 유틸리티 등을 제공하여 맞춤형 카탈로그를 단시간에 구축할 수 있도록 돕는 도구 모음이다.

사용자는 이 베이스라인을 기반으로 기능을 확장하고, AI Scaffold를 활용해 에이전트 기반 코딩 루프(Agentic Coding Loop)를 가동할 수 있다.

## 3. Baseline Product

### 기본 원칙

도메인별로 카탈로그를 개별 구현할 때 발생하는 '중복 구축'과 '일관성 결여' 문제를 방지하기 위해 다음 원칙을 준수한다.

- **DataHub 기반 백엔드**: DataHub를 필수 백엔드로 활용하여 메타데이터를 저장하고, 이를 단일 진실 공급원(SSOT)으로 관리한다.
- **API 컨벤션 준수**: 도메인이 다르더라도 통일된 API 규격을 적용하여 시스템 간 일관성을 유지한다.

### 시스템 구조

DataSpoke는 크게 4가지 컴포넌트로 구성된다.

```
┌───────────────────────────────────────────────┐
│                 DataSpoke UI                  │
└───────────────────────┬───────────────────────┘
                        │
┌───────────────────────▼───────────────────────┐
│                DataSpoke API                  │
│         /api/v1/spoke/[de|da|dg]/...          │
└───────────┬───────────────────────┬───────────┘
            │                       │
┌───────────▼───────────┐ ┌─────────▼───────────┐
│       DataHub         │ │      DataSpoke      │
│    (metadata SSOT)    │ │  Backend / Pipeline │
└───────────────────────┘ └─────────────────────┘

              High Level Architecture
```

- **DataSpoke UI**: 각 그룹별 맞춤형 솔루션으로 진입하는 포털 형태의 화면을 제공한다.
- **DataSpoke API**: 사용자 그룹별로 분리된 계층적 URI 구조를 가진다.
- **DataSpoke Backend/Pipeline**: 인제스션, 품질 검증, 문서화 등 핵심 로직을 처리한다.
- **DataHub**: 메타데이터 저장 및 단일 진실 공급원(SSOT) 역할을 수행한다.

```
┌─────────────────────────────────────────────┐
│  Data Hub & Spokes                   Login  │
│─────────────────────────────────────────────│
│                                             │
│              (DE)                           │
│                 \                           │
│                  \                          │
│                   (Hub)----(DG)             │
│                  /                          │
│                 /                           │
│              (DG)                           │
│                                             │
└─────────────────────────────────────────────┘
                 UI Main Page
```

### 사용자 그룹별 맞춤 기능

#### 데이터 엔지니어(DE) 그룹

- **세부 기술 스펙 수집 (Ingestion)**: 스토리지 압축 포맷, 카프카 토픽 복제 수준 등 플랫폼별 심층 기술 메타데이터를 수집한다.
- **Online Data Validator**: 데이터 시계열 모니터링 및 검증을 수행한다. 실제 저장소에 데이터를 입력하지 않고도 검증 통과 여부만 확인하거나, 과거 시점의 데이터를 검증하는 API를 제공한다.
- **데이터 문서화 자동 제안**:
  - 소스 코드(GitHub 등) 레퍼런스를 기반으로 문서화를 제안한다.
  - 유사한 테이블 간의 차이점을 명확히 구분하여 기술하도록 제안한다.
  - 전사 공통 택소노미 및 온톨로지를 제안하고, 승인 시 이를 기반으로 수정을 제안한다.

#### 데이터 분석가(DA) 그룹

- **자연어 기반 검색**: 자연어로 원하는 데이터 테이블을 직관적으로 탐색한다.
- **Text-to-SQL 최적화 메타데이터**: 기술 스펙보다는 데이터 내용에 집중하여, AI가 SQL을 정확히 생성할 수 있도록 정제된 메타데이터를 제공한다.
- **Online Data Validator**: DE 그룹과 동일한 기능을 활용한다.

#### 데이터 거버넌스(DG) 그룹

- **전사 지표 시계열 모니터링**: 플랫폼별 데이터 수, 총 용량, 가용 데이터 비율(다운타임) 등을 대시보드로 관리한다.
- **다각도 데이터 조망**:
  - 택소노미/온톨로지 그래프 기반 시각화 및 통계량에 따른 데이터셋 컬러링/사이징(2D/3D)을 지원한다.
  - 메달리온 아키텍처(Medallion Architecture) 기반의 데이터셋 조망을 지원한다.

## 4. AI Scaffold

단계별 작업을 위한 커맨드와 스킬(Skill)을 제공한다.

- **개발 환경 셋업**
  - GitHub 클론 및 레퍼런스 데이터 셋업 도구
  - 로컬 Kubernetes 클러스터 기반의 개발 환경 구축 도구
- **개발 계획 수립 (Planning)**
  - 기능 스펙 작성: `spec/feature/spoke` 디렉토리 이하에 사용자 그룹별 기능을 정의한다. 질의응답을 통해 인제스션, 품질 등 분야별 스펙 초안 생성을 지원한다.
  - 세부 구현 계획 수립: `spec/plan` 디렉토리 이하에 현재 구현 상태와 환경을 고려한 작업 계획을 작성한다. AI 코딩 방식(Skill, Sub-agent 구성 등)을 제안받고 스캐폴드를 보강한다.
