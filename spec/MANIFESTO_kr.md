# DataSpoke Baseline

AI Data Catalog Starter: Productized Scaffold to Generate Custom Solutions

![DataSpoke Concept](../assets/dataspoke_concept.jpg)

---

## 1. 배경

### 맞춤형 솔루션의 필요성

데이터 카탈로그 솔루션(e.g. DataHub, Dataplex, OpenMetadata)은 폭넓은 기능을 제공하지만, 실제 활용도는 그 잠재력에 미치지 못하는 경우가 많다. 근본 원인은 모두를 만족시키려다 누구에게도 최적화되지 못했기 때문이다.

- 사용자 그룹마다 요구가 근본적으로 다르다. 데이터 엔지니어는 세부 기술 스펙과 파이프라인 비용을, 데이터 분석가는 text-to-SQL을 위한 도메인 중심 메타데이터를, 데이터 스튜어드는 가용성 지표와 품질 검사 이력을, 보안팀은 PII 활용 현황을 한눈에 보고 싶어 한다. 단일 UI로 이 모든 목적을 잘 소화하기는 어렵다.

- UI를 넘어 도메인 특화 기능도 필요하다 — ML 기반 맞춤형 데이터 품질 모듈, 기존 수집 구조에 맞지 않는 비표준 데이터 소스 등록 등 범용 카탈로그가 지원하지 못하는 확장이 요구된다.

### AI 시대의 새로운 요구 조건

LLM과 AI 에이전트가 실무에 도입됨에 따라, 데이터 카탈로그는 메타데이터 저장소를 넘어 두 가지 새로운 기능을 수행해야 한다.

- **Online Verifier (실시간 검증)**: AI 코딩 루프 내에서 파이프라인 결과물을 실시간 검증한다. RAG나 MCP(Model Context Protocol)를 통해 카탈로그를 연결하면, TDD 방식처럼 검증을 먼저 설정하고 파이프라인을 개발하는 워크플로우가 가능하다.

- **Self-Organization & Self-Purification (자기 조직화 및 자기 정화)**: AI를 활용해 데이터 택소노미 및 온톨로지를 설계하고, 정합성을 자동으로 점검·교정한다. 비즈니스 데이터가 복잡해질수록 전사 스키마와 테이블/컬럼 정의를 최신 상태로 유지해야 한다. 데이터 카탈로그가 이 작업을 수행하기에 가장 적합한 컴포넌트다.

## 2. 프로젝트 정의

본 프로젝트는 코딩 에이전트를 활용한 맞춤형 데이터 카탈로그의 빠른 제작 틀을 제공하여 위 문제를 해결한다.

프로젝트명 **DataSpoke**는 기존 DataHub를 Hub로, 각 조직에 맞춘 특화 확장판을 바퀴살(Spoke)로 정의하는 구조에서 비롯되었다.

이 저장소의 산출물은 두 가지다.

- **Baseline Product** — AI 시대 카탈로그의 필수 기능을 사전 구현한 것이다. 데이터 엔지니어(DE), 데이터 분석가(DA), 데이터 거버넌스 담당자(DG)를 대상으로 한다.
- **AI Scaffold** — 컨벤션, 개발 스펙, 환경 설정, Claude Code 유틸리티를 제공하여 맞춤형 카탈로그를 단시간에 구축할 수 있게 한다.

사용자는 이 베이스라인을 확장하고, AI Scaffold를 활용해 에이전트 기반 코딩 루프(Agentic Coding Loop)를 가동한다.

## 3. Baseline Product

### 기본 원칙

중복 구축과 도메인 간 불일치를 방지하기 위해:

- **DataHub 기반 백엔드**: DataHub가 메타데이터를 저장하고 단일 진실 공급원(SSOT) 역할을 한다.
- **API 컨벤션 준수**: 통일된 API 규격으로 모든 도메인의 일관성을 유지한다.

### 시스템 구조

DataSpoke는 네 가지 컴포넌트로 구성된다.

```
┌───────────────────────────────────────────────┐
│                 DataSpoke UI                  │
└───────────────────────┬───────────────────────┘
                        │
┌───────────────────────▼───────────────────────┐
│                DataSpoke API                  │
└───────────┬───────────────────────┬───────────┘
            │                       │
┌───────────▼───────────┐ ┌─────────▼───────────┐
│       DataHub         │ │      DataSpoke      │
│    (metadata SSOT)    │ │  Backend / Pipeline │
└───────────────────────┘ └─────────────────────┘

              High Level Architecture
```

- **DataSpoke UI**: 사용자 그룹별 진입점을 갖춘 포털 형태의 인터페이스.
  ```
  ┌─────────────────────────────────────────────┐
  │  Data Hub & Spokes                   Login  │
  │─────────────────────────────────────────────│
  │                                             │
  │              (DE)                           │
  │                 \                           │
  │                  \                          │
  │                   (Hub)----(DG)             │
  │                  /                          │
  │                 /                           │
  │              (DA)                           │
  │                                             │
  └─────────────────────────────────────────────┘
                  UI Main Page
  ```
- **DataSpoke API**: 3계층 URI 구조.
  ```
  /api/v1/spoke/common/…       # 사용자 그룹 공통 기능
  /api/v1/spoke/[de|da|dg]/…   # 사용자 그룹별 전용 기능
  /api/v1/hub/…                # DataHub 패스스루 (클라이언트용 선택적 인그레스)
  ```
- **DataSpoke Backend/Pipeline**: 인제스션, 품질 검증, 문서화, 온톨로지 생성 등 핵심 로직 처리.
- **DataHub**: 메타데이터 SSOT.

### 사용자 그룹별 맞춤 기능

#### 데이터 엔지니어(DE) 그룹

- **세부 기술 스펙 수집 (Ingestion)**: 스토리지 압축 포맷, 카프카 토픽 복제 수준 등 플랫폼별 심층 기술 메타데이터를 수집한다.
- **Online Data Validator**: 데이터 시계열 모니터링 및 검증을 수행한다. 실제 저장소에 쓰지 않는 건식 검증(dry-run)과 과거 시점 데이터 검증 API를 제공한다.
- **데이터 문서화 자동 제안**:
  - 소스 코드(GitHub 등) 레퍼런스 기반 문서화를 제안한다.
  - 유사 테이블 간의 차이를 명확히 구분하여 기술한다.
  - 전사 택소노미 및 온톨로지 표준을 제안하고, 승인 시 이를 기반으로 수정을 제안한다.

#### 데이터 분석가(DA) 그룹

- **자연어 기반 검색**: 자연어로 데이터 테이블을 직관적으로 탐색한다.
- **Text-to-SQL 최적화 메타데이터**: 기술 스펙보다 데이터 내용에 집중한 정제 메타데이터를 제공하여 AI의 SQL 생성 정확도를 높인다.
- **Online Data Validator**: DE 그룹과 동일한 기능을 활용한다.

#### 데이터 거버넌스(DG) 그룹

- **전사 지표 시계열 모니터링**: 플랫폼별 데이터셋 수, 총 용량, 가용 데이터 비율(다운타임) 등을 추적하는 대시보드.
- **다각도 데이터 조망**:
  - 택소노미/온톨로지 그래프 시각화 및 통계량 기반 데이터셋 컬러링/사이징(2D/3D).
  - 메달리온 아키텍처(Medallion Architecture) 기반 데이터셋 조망.

## 4. AI Scaffold

단계별 개발 워크플로우를 위한 커맨드와 스킬을 제공한다.

- **개발 환경 셋업**
  - GitHub 클론 및 레퍼런스 데이터 셋업
  - 로컬 Kubernetes 클러스터 기반 개발 환경 구축
- **개발 계획 수립 (Planning)**
  - 기능 스펙 작성: 질의응답을 통해 사용자 그룹별 기능을 `spec/feature/spoke/`에, 공통 기능을 `spec/feature/`에 정의한다.
  - 구현 계획 수립: `spec/impl/`에 현재 구현 상태와 환경을 고려한 작업 계획을 작성한다. AI 코딩 방식(스킬/서브에이전트 구성 등)을 제안받고 스캐폴드를 보강한다.
